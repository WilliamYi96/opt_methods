# Optimization methods
### Benchmarking optimization methods on convex problems.
## Structure
### First order
Gradient Descent (GD), Polyak's Heavy-ball, Incremental Gradient (IG), Mirror Descent (MD), Nesterov's acceleration (Nesterov).
Adaptive: Adagrad, AdGD, Accelerated AdGD (AdgdAccel), Polyak.
### Second order
Newton.
Stochastic: Stochastic Newton, Stochastic Cubic Regularization.
Qausi-Newotn: BFGS, DFP, Shor, SR1.
### Stochastic first order
SGD, Root=SGD, Stochastic Variance Reduced Gradient (SVRG), Random Reshuffling (RR).
### Notebooks
Examples of running the methods on convex problems: linear regression (to appear), logistic regression, entropy minimization (to appear).